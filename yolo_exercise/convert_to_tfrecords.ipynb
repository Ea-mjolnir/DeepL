{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b97cac9-113e-483f-af7d-6ea826fb217f",
   "metadata": {},
   "source": [
    "# Creating TFRecords from CSV created by https://www.robots.ox.ac.uk/~vgg/software/via/via_demo.html\n",
    "\n",
    "This script is designed to convert annotations from a CSV file (formatted by VGG Image Annotator) into TensorFlow's TFRecord format.\n",
    "\n",
    "### Input CSV File Format\n",
    "\n",
    "The CSV file should have the following columns:\n",
    "\n",
    "    filename: Name of the image file.\n",
    "    region_shape_attributes: Bounding box details (e.g., x, y, width, height).\n",
    "    region_attributes: Additional information about each region (e.g., object class).\n",
    "\n",
    "### Expected Directory Structure\n",
    "\n",
    "    data/: Directory containing the image files referenced in the CSV file.\n",
    "    CSV file: The annotation file created by VGG Image Annotator.\n",
    "\n",
    "### Script Functionality\n",
    "\n",
    "    Read CSV File: Parses the CSV file to extract bounding box and class information.\n",
    "    Filter Annotations: Focuses on the specified object classes (person, bicycle, car).\n",
    "    Read and Encode Images: Reads images from the data/ directory and encodes them.\n",
    "    Convert to TFRecord: Converts the data to TFRecord format and writes to a file.\n",
    "\n",
    "### How to Use\n",
    "\n",
    "    Place the CSV file and the data/ directory in the same directory as the script.\n",
    "    Update the script with the path to your CSV file and output TFRecord file.\n",
    "    Run the script. This will generate a TFRecord file in the specified output location.\n",
    "    This file can then be used as dataset for yolov3-tf2 training (training_yolov2-tf2.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8f1ace-91ff-429f-b3c2-590ce434b232",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change X to the GPU number you want to use,\n",
    "# otherwise you will get a Python error\n",
    "# e.g. USE_GPU = 4\n",
    "USE_GPU = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d8618-7562-4dfe-8788-705330650c87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import TensorFlow \n",
    "import tensorflow as tf\n",
    "\n",
    "# Print the installed TensorFlow version\n",
    "print(f'TensorFlow version: {tf.__version__}\\n')\n",
    "\n",
    "# Get all GPU devices on this server\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# Print the name and the type of all GPU devices\n",
    "print('Available GPU Devices:')\n",
    "for gpu in gpu_devices:\n",
    "    print(' ', gpu.name, gpu.device_type)\n",
    "    \n",
    "# Set only the GPU specified as USE_GPU to be visible\n",
    "tf.config.set_visible_devices(gpu_devices[USE_GPU], 'GPU')\n",
    "\n",
    "# Get all visible GPU  devices on this server\n",
    "visible_devices = tf.config.get_visible_devices('GPU')\n",
    "\n",
    "# Print the name and the type of all visible GPU devices\n",
    "print('\\nVisible GPU Devices:')\n",
    "for gpu in visible_devices:\n",
    "    print(' ', gpu.name, gpu.device_type)\n",
    "    \n",
    "# Set the visible device(s) to not allocate all available memory at once,\n",
    "# but rather let the memory grow whenever needed\n",
    "for gpu in visible_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd219a9-9ed0-426f-8794-7335253f3a87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from collections import namedtuple\n",
    "\n",
    "def int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def float_list_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def bytes_list_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "def int64_list_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "def class_text_to_int(row_label):\n",
    "    if row_label == 'person':\n",
    "        return 1\n",
    "    elif row_label == 'bicycle':\n",
    "        return 2\n",
    "    elif row_label == 'car':\n",
    "        return 3\n",
    "    else:\n",
    "        None\n",
    "        \n",
    "def create_tf_example(group, path):\n",
    "    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
    "        encoded_img = fid.read()\n",
    "    \n",
    "    encoded_img_io = BytesIO(encoded_img)\n",
    "    image = Image.open(encoded_img_io)\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = group.filename.encode('utf8')\n",
    "    image_format = b'png'  # or b'jpeg' if your images are in jpeg format\n",
    "\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for index, row in group.object.iterrows():\n",
    "        classes_text.append(row['class'].encode('utf8'))\n",
    "        classes.append(class_text_to_int(row['class']))\n",
    "\n",
    "        x = row['x']\n",
    "        y = row['y']\n",
    "        w = row['width']\n",
    "        h = row['height']\n",
    "\n",
    "        xmin = x / width\n",
    "        xmax = (x + w) / width\n",
    "        ymin = y / height\n",
    "        ymax = (y + h) / height\n",
    "\n",
    "        xmins.append(xmin)\n",
    "        xmaxs.append(xmax)\n",
    "        ymins.append(ymin)\n",
    "        ymaxs.append(ymax)\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': int64_feature(height),\n",
    "        'image/width': int64_feature(width),\n",
    "        'image/filename': bytes_feature(filename),\n",
    "        'image/source_id': bytes_feature(filename),\n",
    "        'image/encoded': bytes_feature(encoded_img),\n",
    "        'image/format': bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': float_list_feature(ymaxs),\n",
    "        'image/object/class/text': bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example\n",
    "\n",
    "\n",
    "\n",
    "# Assuming you have the following helper function\n",
    "def split(df, group):\n",
    "    data = namedtuple('data', ['filename', 'object'])\n",
    "    gb = df.groupby(group)\n",
    "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
    "\n",
    "# Read the CSV file\n",
    "annotations_df = pd.read_csv('via_project_15Jan2024_10h57m_csv.csv')\n",
    "annotations_df['region_attributes'] = annotations_df['region_attributes'].apply(json.loads)\n",
    "annotations_df['class'] = annotations_df['region_attributes'].apply(lambda x: x['type'])\n",
    "annotations_df['x'] = annotations_df['region_shape_attributes'].apply(lambda x: json.loads(x)['x'])\n",
    "annotations_df['y'] = annotations_df['region_shape_attributes'].apply(lambda x: json.loads(x)['y'])\n",
    "annotations_df['width'] = annotations_df['region_shape_attributes'].apply(lambda x: json.loads(x)['width'])\n",
    "annotations_df['height'] = annotations_df['region_shape_attributes'].apply(lambda x: json.loads(x)['height'])\n",
    "\n",
    "# Filter out unwanted classes\n",
    "annotations_df = annotations_df[annotations_df['class'].isin(['person', 'bicycle', 'car'])]\n",
    "\n",
    "output_path = 'train.record'\n",
    "writer = tf.io.TFRecordWriter(output_path)\n",
    "path = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "grouped = split(annotations_df, 'filename')\n",
    "for group in grouped:\n",
    "    tf_example = create_tf_example(group, path)\n",
    "    writer.write(tf_example.SerializeToString())\n",
    "\n",
    "writer.close()\n",
    "output_path = os.path.join(os.getcwd(), output_path)\n",
    "print('Successfully created the TFRecord file:', output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30591b49-6a70-4d58-8915-f56b0a062446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
