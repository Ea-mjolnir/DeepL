{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8f1ace-91ff-429f-b3c2-590ce434b232",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change X to the GPU number you want to use,\n",
    "# otherwise you will get a Python error\n",
    "# e.g. USE_GPU = 4\n",
    "USE_GPU = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d8618-7562-4dfe-8788-705330650c87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import TensorFlow \n",
    "import tensorflow as tf\n",
    "\n",
    "# Print the installed TensorFlow version\n",
    "print(f'TensorFlow version: {tf.__version__}\\n')\n",
    "\n",
    "# Get all GPU devices on this server\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# Print the name and the type of all GPU devices\n",
    "print('Available GPU Devices:')\n",
    "for gpu in gpu_devices:\n",
    "    print(' ', gpu.name, gpu.device_type)\n",
    "    \n",
    "# Set only the GPU specified as USE_GPU to be visible\n",
    "tf.config.set_visible_devices(gpu_devices[USE_GPU], 'GPU')\n",
    "\n",
    "# Get all visible GPU  devices on this server\n",
    "visible_devices = tf.config.get_visible_devices('GPU')\n",
    "\n",
    "# Print the name and the type of all visible GPU devices\n",
    "print('\\nVisible GPU Devices:')\n",
    "for gpu in visible_devices:\n",
    "    print(' ', gpu.name, gpu.device_type)\n",
    "    \n",
    "# Set the visible device(s) to not allocate all available memory at once,\n",
    "# but rather let the memory grow whenever needed\n",
    "for gpu in visible_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4583b8fc-4f23-40b0-86b7-4d646b61a3c4",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b4510a-69db-4440-bc9f-d51ad05c91e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from absl import app, flags, logging\n",
    "from absl.flags import FLAGS\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "from tensorflow.keras.callbacks import (\n",
    "    ReduceLROnPlateau,\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    TensorBoard\n",
    ")\n",
    "from yolov3_tf2.models import (\n",
    "    YoloV3, YoloLoss,\n",
    "    yolo_anchors, yolo_anchor_masks\n",
    ")\n",
    "from yolov3_tf2.utils import freeze_all\n",
    "import yolov3_tf2.dataset as dataset\n",
    "\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "ROOT = str(Path.home()) + r'/coursematerial/GIS/DeepLearning/YOLO/'\n",
    "filename_classes =  os.path.join(ROOT,'coco.names')\n",
    "\n",
    "filename_converted_weights = os.path.join(ROOT,'yolov3.tf')\n",
    "\n",
    "flags.DEFINE_string('dataset', 'train.record', 'path to dataset')\n",
    "flags.DEFINE_string('val_dataset', 'train.record', 'path to validation dataset')\n",
    "flags.DEFINE_boolean('tiny', False, 'yolov3 or yolov3-tiny')\n",
    "flags.DEFINE_string('weights', filename_converted_weights, 'path to weights file')\n",
    "flags.DEFINE_string('classes', filename_classes, 'path to classes file')\n",
    "flags.DEFINE_enum('mode', 'fit', ['fit', 'eager_fit', 'eager_tf'],\n",
    "                  'fit: model.fit, '\n",
    "                  'eager_fit: model.fit(run_eagerly=True), '\n",
    "                  'eager_tf: custom GradientTape')\n",
    "flags.DEFINE_enum('transfer', 'fine_tune',\n",
    "                  ['none', 'darknet', 'no_output', 'frozen', 'fine_tune'],\n",
    "                  'none: Training from scratch, '\n",
    "                  'darknet: Transfer darknet, '\n",
    "                  'no_output: Transfer all but output, '\n",
    "                  'frozen: Transfer and freeze all, '\n",
    "                  'fine_tune: Transfer all and freeze darknet only')\n",
    "flags.DEFINE_integer('size', 416, 'image size')\n",
    "flags.DEFINE_integer('epochs', 5, 'number of epochs')\n",
    "flags.DEFINE_integer('batch_size', 8, 'batch size')\n",
    "flags.DEFINE_float('learning_rate', 1e-3, 'learning rate')\n",
    "flags.DEFINE_integer('num_classes', 80, 'number of classes in the model')\n",
    "flags.DEFINE_integer('weights_num_classes', None, 'specify num class for `weights` file if different, '\n",
    "                     'useful in transfer learning with different number of classes')\n",
    "flags.DEFINE_boolean('multi_gpu', False, 'Use if wishing to train with more than 1 GPU.')\n",
    "\n",
    "# Flags are used to define several options for YOLO.\n",
    "#flags.DEFINE_string('classes', filename_classes, 'path to classes file')\n",
    "#flags.DEFINE_string('weights', filename_converted_weights, 'path to weights file')\n",
    "#flags.DEFINE_boolean('tiny', False, 'yolov3 or yolov3-tiny')\n",
    "#flags.DEFINE_integer('size', 416, 'resize images to')\n",
    "#flags.DEFINE_string('tfrecord', None, 'tfrecord instead of image')\n",
    "#flags.DEFINE_integer('num_classes', 80, 'number of classes in the model')\n",
    "FLAGS([sys.argv[0]])\n",
    "\n",
    "\n",
    "def setup_model():\n",
    "    model = YoloV3(FLAGS.size, training=True, classes=FLAGS.num_classes)\n",
    "    anchors = yolo_anchors\n",
    "    anchor_masks = yolo_anchor_masks\n",
    "\n",
    "    # Configure the model for transfer learning\n",
    "    if FLAGS.transfer == 'none':\n",
    "        pass  # Nothing to do\n",
    "    elif FLAGS.transfer in ['darknet', 'no_output']:\n",
    "        # Darknet transfer is a special case that works\n",
    "        # with incompatible number of classes\n",
    "        # reset top layers\n",
    "        if FLAGS.tiny:\n",
    "            model_pretrained = YoloV3Tiny(\n",
    "                FLAGS.size, training=True, classes=FLAGS.weights_num_classes or FLAGS.num_classes)\n",
    "        else:\n",
    "            model_pretrained = YoloV3(\n",
    "                FLAGS.size, training=True, classes=FLAGS.weights_num_classes or FLAGS.num_classes)\n",
    "        model_pretrained.load_weights(FLAGS.weights)\n",
    "\n",
    "        if FLAGS.transfer == 'darknet':\n",
    "            model.get_layer('yolo_darknet').set_weights(\n",
    "                model_pretrained.get_layer('yolo_darknet').get_weights())\n",
    "            freeze_all(model.get_layer('yolo_darknet'))\n",
    "        elif FLAGS.transfer == 'no_output':\n",
    "            for l in model.layers:\n",
    "                if not l.name.startswith('yolo_output'):\n",
    "                    l.set_weights(model_pretrained.get_layer(\n",
    "                        l.name).get_weights())\n",
    "                    freeze_all(l)\n",
    "    else:\n",
    "        # All other transfer require matching classes\n",
    "        model.load_weights(FLAGS.weights)\n",
    "        if FLAGS.transfer == 'fine_tune':\n",
    "            # freeze darknet and fine tune other layers\n",
    "            darknet = model.get_layer('yolo_darknet')\n",
    "            freeze_all(darknet)\n",
    "        elif FLAGS.transfer == 'frozen':\n",
    "            # freeze everything\n",
    "            freeze_all(model)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=FLAGS.learning_rate)\n",
    "    loss = [YoloLoss(anchors[mask], classes=FLAGS.num_classes)\n",
    "            for mask in anchor_masks]\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss,\n",
    "                  run_eagerly=(FLAGS.mode == 'eager_fit'))\n",
    "\n",
    "    return model, optimizer, loss, anchors, anchor_masks\n",
    "\n",
    "\n",
    "model, optimizer, loss, anchors, anchor_masks = setup_model()\n",
    "if FLAGS.dataset:\n",
    "    train_dataset = dataset.load_tfrecord_dataset(\n",
    "        FLAGS.dataset, FLAGS.classes, FLAGS.size)\n",
    "else:\n",
    "    train_dataset = dataset.load_fake_dataset()\n",
    "train_dataset = train_dataset.shuffle(buffer_size=512)\n",
    "train_dataset = train_dataset.batch(FLAGS.batch_size)\n",
    "train_dataset = train_dataset.map(lambda x, y: (\n",
    "    dataset.transform_images(x, FLAGS.size),\n",
    "    dataset.transform_targets(y, anchors, anchor_masks, FLAGS.size)))\n",
    "train_dataset = train_dataset.prefetch(\n",
    "    buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "if FLAGS.val_dataset:\n",
    "    val_dataset = dataset.load_tfrecord_dataset(\n",
    "        FLAGS.val_dataset, FLAGS.classes, FLAGS.size)\n",
    "else:\n",
    "    val_dataset = dataset.load_fake_dataset()\n",
    "val_dataset = val_dataset.batch(FLAGS.batch_size)\n",
    "val_dataset = val_dataset.map(lambda x, y: (\n",
    "    dataset.transform_images(x, FLAGS.size),\n",
    "    dataset.transform_targets(y, anchors, anchor_masks, FLAGS.size)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159fa14d-9e73-4601-bb4f-e615e1e1264c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"start training\")\n",
    "# Eager mode is great for debugging\n",
    "# Non eager graph mode is recommended for real training\n",
    "avg_loss = tf.keras.metrics.Mean('loss', dtype=tf.float32)\n",
    "avg_val_loss = tf.keras.metrics.Mean('val_loss', dtype=tf.float32)\n",
    "\n",
    "for epoch in range(1, FLAGS.epochs + 1):\n",
    "    for batch, (images, labels) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = model(images, training=True)\n",
    "            regularization_loss = tf.reduce_sum(model.losses)\n",
    "            pred_loss = []\n",
    "            for output, label, loss_fn in zip(outputs, labels, loss):\n",
    "                pred_loss.append(loss_fn(label, output))\n",
    "            total_loss = tf.reduce_sum(pred_loss) + regularization_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(\n",
    "            zip(grads, model.trainable_variables))\n",
    "\n",
    "        logging.info(\"{}_train_{}, {}, {}\".format(\n",
    "            epoch, batch, total_loss.numpy(),\n",
    "            list(map(lambda x: np.sum(x.numpy()), pred_loss))))\n",
    "        avg_loss.update_state(total_loss)\n",
    "\n",
    "    for batch, (images, labels) in enumerate(val_dataset):\n",
    "        outputs = model(images)\n",
    "        regularization_loss = tf.reduce_sum(model.losses)\n",
    "        pred_loss = []\n",
    "        for output, label, loss_fn in zip(outputs, labels, loss):\n",
    "            pred_loss.append(loss_fn(label, output))\n",
    "        total_loss = tf.reduce_sum(pred_loss) + regularization_loss\n",
    "\n",
    "        logging.info(\"{}_val_{}, {}, {}\".format(\n",
    "            epoch, batch, total_loss.numpy(),\n",
    "            list(map(lambda x: np.sum(x.numpy()), pred_loss))))\n",
    "        avg_val_loss.update_state(total_loss)\n",
    "\n",
    "    logging.info(\"{}, train: {}, val: {}\".format(\n",
    "        epoch,\n",
    "        avg_loss.result().numpy(),\n",
    "        avg_val_loss.result().numpy()))\n",
    "\n",
    "    avg_loss.reset_states()\n",
    "    avg_val_loss.reset_states()\n",
    "    model.save_weights(\n",
    "        'trained_models/yolov3_train_{}.tf'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d994a13-79a6-441b-93c3-44505a334b85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
